{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1HkgG1noWGbjSmnBPclVsmh9dUzpbrYg6","timestamp":1710386306122}],"authorship_tag":"ABX9TyNXz5155XgUOu4YycqYCTk3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"cmejhzCT3xVr"}},{"cell_type":"markdown","source":["Importing libraries and dependencies\n"],"metadata":{"id":"9Sw7gAg834rY"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import zipfile\n","import os\n","import glob\n","import random\n","import sys\n","\n","import skimage.io                           #Used for imshow function\n","import skimage.transform                    #Used for resize function\n","from skimage.morphology import label        #Used for Run-Length-Encoding RLE to create final submission\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","# Custom IoU metric\n","def mean_iou(y_true, y_pred):\n","    prec = []\n","    for t in np.arange(0.5, 1.0, 0.05):\n","        y_pred_ = tf.to_int32(y_pred > t)\n","        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n","        K.get_session().run(tf.local_variables_initializer())\n","        with tf.control_dependencies([up_opt]):\n","            score = tf.identity(score)\n","        prec.append(score)\n","    return K.mean(K.stack(prec), axis=0)\n","\n","IMG_WIDTH       = 256\n","IMG_HEIGHT      = 256\n","IMG_CHANNELS    = 3\n","\n","print('Python       :', sys.version.split('\\n')[0])\n","print('Numpy        :', np.__version__)\n","print('Skimage      :', skimage.__version__)\n","print('Tensorflow   :', tf.__version__)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DzSnspMS38PE","executionInfo":{"status":"ok","timestamp":1710384939729,"user_tz":-330,"elapsed":7862,"user":{"displayName":"SHRUTHI GUHAN","userId":"10383019386172735120"}},"outputId":"14812925-2df0-4d69-f2ed-6e33135ee46c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Python       : 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n","Numpy        : 1.25.2\n","Skimage      : 0.19.3\n","Tensorflow   : 2.15.0\n"]}]},{"cell_type":"markdown","source":["MOdel Hyperparameters\n"],"metadata":{"id":"v_8In2Qc4xqY"}},{"cell_type":"code","source":["# learning rate\n","LR = 0.001\n","# Custom loss function\n","def dice_coef(y_true, y_pred):\n","    smooth = 1.\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","def bce_dice_loss(y_true, y_pred):\n","    return 0.5 * tf.keras.losses.binary_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)\n","\n","NUM_EPOCHS=25"],"metadata":{"id":"xgQRj2AL42RB","executionInfo":{"status":"ok","timestamp":1710384988927,"user_tz":-330,"elapsed":447,"user":{"displayName":"SHRUTHI GUHAN","userId":"10383019386172735120"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["LOading Images"],"metadata":{"id":"dwg6CNZO49BR"}},{"cell_type":"code","source":["import zipfile\n","for name_data in ['test', 'train']:\n","    tmp_zip = zipfile.ZipFile('../input/sf-dl-nucleus-detection/'+name_data+'.zip')\n","    tmp_zip.extractall(name_data)\n","    tmp_zip.close()\n","\n","# to load the data, we will use the convenient skimage lib\n","def get_X_data(path, output_shape=(None, None)):\n","    '''\n","    Loads images from path/{id}/images/{id}.png into a numpy array\n","    '''\n","    img_paths = ['{0}/{1}/images/{1}.png'.format(path, id) for id in os.listdir(path)]\n","    X_data = np.array([skimage.transform.resize(skimage.io.imread(path)[:,:,:3],\n","                                                output_shape=output_shape,\n","                                                mode='constant',\n","                                                preserve_range=True) for path in img_paths], dtype=np.uint8)  #take only 3 channels/bands\n","\n","    return X_data\n","\n","def get_Y_data(path, output_shape=(None, None)):\n","    '''\n","    Loads and concatenates images from path/{id}/masks/{id}.png into a numpy array\n","     '''\n","    img_paths = [glob.glob('{0}/{1}/masks/*.png'.format(path, id)) for id in os.listdir(path)]\n","\n","    Y_data = []\n","    for i, img_masks in enumerate(img_paths):  #loop through each individual nuclei for an image and combine them together\n","        masks = skimage.io.imread_collection(img_masks).concatenate()  #masks.shape = (num_masks, img_height, img_width)\n","        mask = np.max(masks, axis=0)                                   #mask.shape = (img_height, img_width)\n","        mask = skimage.transform.resize(mask, output_shape=output_shape+(1,), mode='constant', preserve_range=True)  #need to add an extra dimension so mask.shape = (img_height, img_width, 1)\n","        Y_data.append(mask)\n","    Y_data = np.array(Y_data, dtype=np.bool_)\n","\n","    return Y_data\n","\n","# Get training data\n","X_train = get_X_data('train', output_shape=(IMG_HEIGHT,IMG_WIDTH))\n","# Get training data labels\n","Y_train = get_Y_data('train', output_shape=(IMG_HEIGHT,IMG_WIDTH))\n","\n","X_test = get_X_data('test', output_shape=(IMG_HEIGHT,IMG_WIDTH))\n","\n","TRAIN_PATH = 'train/'\n","\n","# Check training data\n","train_ids = next(os.walk(TRAIN_PATH))\n","\n","f, axarr = plt.subplots(2,4)\n","f.set_size_inches(20,10)\n","ix = random.randint(0, len(train_ids[1]))\n","axarr[0,0].imshow(X_train[ix])\n","axarr[0,1].imshow(np.squeeze(Y_train[ix]))\n","\n","axarr[0,2].imshow(X_train[ix])\n","axarr[0,3].imshow(np.squeeze(Y_train[ix]))\n","\n","axarr[1,0].imshow(X_train[ix])\n","axarr[1,1].imshow(np.squeeze(Y_train[ix]))\n","\n","axarr[1,2].imshow(X_train[ix])\n","axarr[1,3].imshow(np.squeeze(Y_train[ix]))\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"WLfqxPai5DA_","executionInfo":{"status":"error","timestamp":1710385187588,"user_tz":-330,"elapsed":434,"user":{"displayName":"SHRUTHI GUHAN","userId":"10383019386172735120"}},"outputId":"862d3b2b-bf5e-45ee-a21d-ad24ac88c5ab"},"execution_count":3,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '../input/sf-dl-nucleus-detection/test.zip'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-03ad8eeac6bd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtmp_zip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/sf-dl-nucleus-detection/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname_data\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtmp_zip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtmp_zip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/sf-dl-nucleus-detection/test.zip'"]}]},{"cell_type":"markdown","source":["Image augmentation"],"metadata":{"id":"VWzo6Ia-5t7T"}},{"cell_type":"code","source":["x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.1, random_state=13)\n","\n","data_gen_args = dict(rotation_range=45.,\n","                         width_shift_range=0.1,\n","                         height_shift_range=0.1,\n","                         shear_range=0.2,\n","                         zoom_range=0.2,\n","                         horizontal_flip=True,\n","                         vertical_flip=True,\n","                         fill_mode='reflect')\n","\n","X_datagen = ImageDataGenerator(**data_gen_args)\n","Y_datagen = ImageDataGenerator(**data_gen_args)\n","test_datagen = ImageDataGenerator()\n","X_datagen_val = ImageDataGenerator()\n","Y_datagen_val = ImageDataGenerator()\n","\n","X_datagen.fit(x_train, augment=True, seed=13)\n","Y_datagen.fit(y_train, augment=True, seed=13)\n","test_datagen.fit(X_test, augment=True, seed=13)\n","X_datagen_val.fit(x_test, augment=True, seed=13)\n","Y_datagen_val.fit(y_test, augment=True, seed=13)\n","\n","X_train_augmented = X_datagen.flow(x_train,  batch_size=15, shuffle=True, seed=13)\n","Y_train_augmented = Y_datagen.flow(y_train,  batch_size=15, shuffle=True, seed=13)\n","test_augmented = test_datagen.flow(X_test, shuffle=False, seed=13)\n","X_train_augmented_val = X_datagen_val.flow(x_test,  batch_size=15, shuffle=True, seed=13)\n","Y_train_augmented_val = Y_datagen_val.flow(y_test,  batch_size=15, shuffle=True, seed=13)\n","\n","train_generator = zip(X_train_augmented, Y_train_augmented)\n","val_generator = zip(X_train_augmented_val, Y_train_augmented_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"aBfFkXLW559Q","executionInfo":{"status":"error","timestamp":1710385313728,"user_tz":-330,"elapsed":547,"user":{"displayName":"SHRUTHI GUHAN","userId":"10383019386172735120"}},"outputId":"f1713b59-32f1-4d76-9f34-487ed49e9b84"},"execution_count":4,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'X_train' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-e5db2b9706d6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m data_gen_args = dict(rotation_range=45.,\n\u001b[1;32m      4\u001b[0m                          \u001b[0mwidth_shift_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                          \u001b[0mheight_shift_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"]}]},{"cell_type":"markdown","source":["Model building"],"metadata":{"id":"7sioTxCE6MC5"}},{"cell_type":"code","source":["tf.keras.backend.clear_session()\n","nb_filter = [32,64,128,256,512]\n","# Build U-Net++ model\n","inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n","s = Lambda(lambda x: x / 255) (inputs)\n","\n","\n","c1 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n","c1 = Dropout(0.5) (c1)\n","c1 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n","c1 = Dropout(0.5) (c1)\n","p1 = MaxPooling2D((2, 2), strides=(2, 2)) (c1)\n","\n","c2 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n","c2 = Dropout(0.5) (c2)\n","c2 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n","c2 = Dropout(0.5) (c2)\n","p2 = MaxPooling2D((2, 2), strides=(2, 2)) (c2)\n","\n","up1_2 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up12', padding='same')(c2)\n","conv1_2 = concatenate([up1_2, c1], name='merge12', axis=3)\n","c3 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_2)\n","c3 = Dropout(0.5) (c3)\n","c3 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n","c3 = Dropout(0.5) (c3)\n","\n","conv3_1 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n","conv3_1 = Dropout(0.5) (conv3_1)\n","conv3_1 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3_1)\n","conv3_1 = Dropout(0.5) (conv3_1)\n","pool3 = MaxPooling2D((2, 2), strides=(2, 2), name='pool3')(conv3_1)\n","\n","up2_2 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up22', padding='same')(conv3_1)\n","conv2_2 = concatenate([up2_2, c2], name='merge22', axis=3) #x10\n","conv2_2 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_2)\n","conv2_2 = Dropout(0.5) (conv2_2)\n","conv2_2 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_2)\n","conv2_2 = Dropout(0.5) (conv2_2)\n","\n","up1_3 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up13', padding='same')(conv2_2)\n","conv1_3 = concatenate([up1_3, c1, c3], name='merge13', axis=3)\n","conv1_3 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_3)\n","conv1_3 = Dropout(0.5) (conv1_3)\n","conv1_3 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_3)\n","conv1_3 = Dropout(0.5) (conv1_3)\n","\n","conv4_1 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pool3)\n","conv4_1 = Dropout(0.5) (conv4_1)\n","conv4_1 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv4_1)\n","conv4_1 = Dropout(0.5) (conv4_1)\n","pool4 = MaxPooling2D((2, 2), strides=(2, 2), name='pool4')(conv4_1)\n","\n","up3_2 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up32', padding='same')(conv4_1)\n","conv3_2 = concatenate([up3_2, conv3_1], name='merge32', axis=3) #x20\n","conv3_2 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3_2)\n","conv3_2 = Dropout(0.5) (conv3_2)\n","conv3_2 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3_2)\n","conv3_2 = Dropout(0.5) (conv3_2)\n","\n","up2_3 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up23', padding='same')(conv3_2)\n","conv2_3 = concatenate([up2_3, c2, conv2_2], name='merge23', axis=3)\n","conv2_3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_3)\n","conv2_3 = Dropout(0.5) (conv2_3)\n","conv2_3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_3)\n","conv2_3 = Dropout(0.5) (conv2_3)\n","\n","up1_4 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up14', padding='same')(conv2_3)\n","conv1_4 = concatenate([up1_4, c1, c3, conv1_3], name='merge14', axis=3)\n","conv1_4 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_4)\n","conv1_4 = Dropout(0.5) (conv1_4)\n","conv1_4 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_4)\n","conv1_4 = Dropout(0.5) (conv1_4)\n","\n","conv5_1 = Conv2D(512, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pool4)\n","conv5_1 = Dropout(0.5) (conv5_1)\n","conv5_1 = Conv2D(512, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv5_1)\n","conv5_1 = Dropout(0.5) (conv5_1)\n","\n","up4_2 = Conv2DTranspose(nb_filter[3], (2, 2), strides=(2, 2), name='up42', padding='same')(conv5_1)\n","conv4_2 = concatenate([up4_2, conv4_1], name='merge42', axis=3)\n","#x30\n","conv4_2 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv4_2)\n","conv4_2 = Dropout(0.5) (conv4_2)\n","conv4_2 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv4_2)\n","conv4_2 = Dropout(0.5) (conv4_2)\n","\n","up3_3 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up33', padding='same')(conv4_2)\n","conv3_3 = concatenate([up3_3, conv3_1, conv3_2], name='merge33', axis=3)\n","conv3_3 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3_3)\n","conv3_3 = Dropout(0.5) (conv3_3)\n","conv3_3 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3_3)\n","conv3_3 = Dropout(0.5) (conv3_3)\n","\n","up2_4 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up24', padding='same')(conv3_3)\n","conv2_4 = concatenate([up2_4, c2, conv2_2, conv2_3], name='merge24', axis=3)\n","conv2_4 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_4)\n","conv2_4 = Dropout(0.5) (conv2_4)\n","conv2_4 = Conv2D(64, (3, 3), activation='elu', kernel_initialize\n","r='he_normal', padding='same') (conv2_4)\n","conv2_4 = Dropout(0.5) (conv2_4)\n","\n","up1_5 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up15', padding='same')(conv2_4)\n","conv1_5 = concatenate([up1_5, c1, c3, conv1_3, conv1_4], name='merge15', axis=3)\n","conv1_5 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_5)\n","conv1_5 = Dropout(0.5) (conv1_5)\n","conv1_5 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_5)\n","conv1_5 = Dropout(0.5) (conv1_5)\n","\n","nestnet_output_4 = Conv2D(1, (1, 1), activation='sigmoid', kernel_initializer = 'he_normal',  name='output_4', padding='same')(conv1_5)\n","\n","model = Model([inputs], [nestnet_output_4])\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR), loss=bce_dice_loss)\n","\n","tf.keras.utils.plot_model(\n","    model,\n","    show_shapes=False,\n","    show_dtype=False,\n","    show_layer_names=True,\n","    rankdir='TB',\n","    expand_nested=False,\n","    dpi=46,\n","    layer_range=None\n",")\n",""],"metadata":{"id":"mNTJIHrE6Zjk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Running the model"],"metadata":{"id":"aCmTFmKt7b4o"}},{"cell_type":"code","source":["checkpoint = ModelCheckpoint('best_model.hdf5' ,\n","                             monitor = 'val_loss',\n","                             verbose = 1,\n","                             save_best_only=True,\n","                             mode = 'min',\n","                             save_weights_only=True,\n","                             save_freq='epoch'\n","                            )\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3,\n","                              patience=5, min_lr=0.00005)\n","\n","callbacks_list = [checkpoint, reduce_lr]\n","\n","# Fit model\n","history = model.fit(train_generator,\n","                    validation_data=val_generator,\n","                    steps_per_epoch=len(X_train)/(6),\n","                    validation_steps=10,\n","                    callbacks=callbacks_list,\n","                    epochs=NUM_EPOCHS,\n","                    verbose=1,)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"tbF51PSJ7dxl","executionInfo":{"status":"error","timestamp":1710385778228,"user_tz":-330,"elapsed":592,"user":{"displayName":"SHRUTHI GUHAN","userId":"10383019386172735120"}},"outputId":"10b588df-7de4-4c69-b195-07c1d03c56cf"},"execution_count":5,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-6722b83634b9>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m history = model.fit(train_generator, \n\u001b[0m\u001b[1;32m     16\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"markdown","source":["Plotting the loss"],"metadata":{"id":"MzZRZu1t79Rd"}},{"cell_type":"code","source":["def plot_loss_history(history):\n","    # validation losses\n","    val_loss = history.history['val_loss']\n","    loss = history.history['loss']\n","\n","    plt.title('Loss')\n","    plt.plot(val_loss, 'r', loss, 'b')\n","    plt.show()\n","\n","plot_loss_history(history)"],"metadata":{"id":"TCrtcv4I7_xl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualization of result"],"metadata":{"id":"KcMcLNa88Dcg"}},{"cell_type":"code","source":["Y_predict = model.predict(X_train, verbose=1)\n","train_ids = next(os.walk('train'))\n","test_ids = next(os.walk('test'))\n","# Check predict data\n","f, axarr = plt.subplots(2,3)\n","f.set_size_inches(20,10)\n","ix = random.randint(0, len(train_ids[1]))\n","axarr[0,0].imshow(X_train[ix])\n","axarr[0,0].set_title('Microscope')\n","axarr[0,1].imshow(np.squeeze(Y_predict[ix]))\n","axarr[0,1].set_title('\"Predicted\" Masks')\n","axarr[0,2].imshow(np.squeeze(Y_train[ix]))\n","axarr[0,2].set_title('\"GroundTruth\" Masks')\n","\n","axarr[1,0].imshow(X_train[ix])\n","axarr[1,0].set_title('Microscope')\n","axarr[1,1].imshow(np.squeeze(Y_predict[ix]))\n","axarr[1,1].set_title('\"Predicted\" Masks')\n","axarr[1,2].imshow(np.squeeze(Y_train[ix]))\n","axarr[1,2].set_title('\"GroundTruth\" Masks')\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"p_E-zbwG8IQx","executionInfo":{"status":"error","timestamp":1710385881845,"user_tz":-330,"elapsed":674,"user":{"displayName":"SHRUTHI GUHAN","userId":"10383019386172735120"}},"outputId":"94a88ff6-2152-4f2c-c2be-b6c5124865a5"},"execution_count":6,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-1bfabda94cc8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Check predict data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"markdown","source":["Using models to predict the labels"],"metadata":{"id":"oI61fg_z8W2q"}},{"cell_type":"code","source":["Y_hat = model.predict(X_test, verbose=1)\n","Y_hat.shape\n","idx = random.randint(0, len(test_ids[1]))\n","print(X_test[idx].shape)\n","skimage.io.imshow(X_test[idx])\n","plt.show();\n","skimage.io.imshow(Y_hat[idx][:,:,0])\n","plt.show();"],"metadata":{"id":"jpXIJ3NF8egE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Training"],"metadata":{"id":"lsUVW86s8kt-"}}]}